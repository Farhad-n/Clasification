{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "Data preparation will include the augmented images. \n",
    "### Steps\n",
    "1. Set the paths to data\n",
    "2. Convert All images to the same dimension  \n",
    "3. Convert to NumPy array\n",
    "4. Change the data type to Unsigned integer (space and file size consideration).\n",
    "5. Create the labels for the images\n",
    "6. Save the data file for later use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# initialization\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy \n",
    "import PIL\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "import deepdish as dd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Concatenate, Dense, Dropout, Flatten, Activation\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import image\n",
    "\n",
    "%matplotlib inline\n",
    "K.set_image_dim_ordering( 'tf' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# directory structure of the data\n",
    "\n",
    "dpath_train = '/home/ubuntu/train'      # Data path to training data set\n",
    "dpath_test  = '/home/ubuntu/test'       # Data path to test data set\n",
    "dpath       = '/home/ubuntu'\n",
    "label_f     = '/home/ubuntu/labels.csv' # Path to the label file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start processing the train images\n",
    "* ** Get the data **\n",
    "* ** Resize and convert to numpy array **\n",
    "* ** Add the 4th axis**\n",
    "* ** concatenate images** \n",
    "* ** Store as unsigned** this will keep the file size small and manageable.\n",
    "* ** create the labels for the images** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long way to create the X_test data set. This code is here for legacy reason. (python code)\n",
    "** This data set will be used in the CNN models and X_train needs to be normalized NumPy array with type \"float32\" **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10222/10222 [58:19<00:00,  1.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# Preparing the input files Following loop will read the csv file for labels\n",
    "# Make sure we are in the correct directory then rea the csv file for all the different breeds\n",
    "\n",
    "os.chdir(dpath)\n",
    "id_label= pd.read_csv(label_f)\n",
    "\n",
    "os.chdir(dpath_train)    # need to be in train data dir\n",
    "# these are the files in the train directory\n",
    "dogs = sorted(glob.glob('*.jpg'))\n",
    "\n",
    "# Size for all images.  we have selected the 224 since the VGG 19 pretrained model we will use needs to\n",
    "# be in 224 X 224 shape.\n",
    "im_W= 224\n",
    "im_H= 224\n",
    "\n",
    "# create X_train and y_train  with rescaling the images\n",
    "\n",
    "# rescale is a function we will call in for loop\n",
    "def rescale(image):\n",
    "    org_image = PIL.Image.open(image)\n",
    "    trans_image = org_image.resize( (im_W, im_H) )\n",
    "    tempAry = np.array(trans_image)\n",
    "    tempAry = np.expand_dims(tempAry, axis = 0)    \n",
    "    return tempAry\n",
    "\n",
    "# declearing some varialbles for loop counter and book keeping\n",
    "flag = 0\n",
    "X_train=[]  #Training vector\n",
    "y_train=[]\n",
    "Count=0\n",
    "for dog in tqdm(dogs):\n",
    "#    Count+=1\n",
    "#    if Count==11000:  # debug just to see if the loop is working.\n",
    "#        break\n",
    "    if flag == 0:  #. this is used to handel the first picture. should come up with elegant situation.\n",
    "        X_train=rescale(dog)\n",
    "        flag=1\n",
    "    else :   \n",
    "        X_train=np.append(X_train,rescale(dog),axis=0) # creat a numpy array for tarining.  \n",
    "\n",
    "#building y_train \n",
    "    newFlag = 0\n",
    "    for x in range(id_label.shape[0]):\n",
    "    \n",
    "        if id_label.iloc[x,0] == dog[:-4]:       # Pilling off the \".jpg\" from file name\n",
    "            y_train.append(id_label.iloc[x,1]) \n",
    "            id_label.drop([x])\n",
    "            newFlag = 1\n",
    "            break\n",
    "# The following can be added to the above loop to make sure indexing is working correctly and not missing anything. \n",
    "# Don't need it in reqular run \n",
    "#    if newFlag == 0:\n",
    "#        y_train.append(\"Oops!\") \n",
    "X_train= X_train.astype('float32' )/ 255  #normalize the X_train.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dingo'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique Dog Breed Numbers =  120\n"
     ]
    }
   ],
   "source": [
    "# Now let's make sure we have all the unique dog names identified and check the total number.\n",
    "\n",
    "unique_Dog_Breed = []\n",
    "for i in y_train:\n",
    "    if i not in unique_Dog_Breed:\n",
    "        unique_Dog_Breed.append(i)\n",
    "    \n",
    "unique_Dog_Breed.sort()   # Now sort the unique label alphabetically. Next, we need to count howmany unique label\n",
    "\n",
    "count = 0\n",
    "unique_Dog_Breed_Num = []   # integer associated with every unique Dog name\n",
    "\n",
    "# with the next loops we are creating integers for each unique label. in preparation of catagorizing the Y.\n",
    "\n",
    "for i in unique_Dog_Breed:\n",
    "    unique_Dog_Breed_Num.append([i, count])\n",
    "    count += 1\n",
    "\n",
    "for i in range(len(y_train)):\n",
    "    for j in unique_Dog_Breed_Num:\n",
    "        if y_train[i] == j[0]:\n",
    "            y_train[i] = j[1]\n",
    "            break\n",
    "\n",
    "print(\"unique Dog Breed Numbers = \",len(unique_Dog_Breed_Num))\n",
    "y_train = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Shuffling \n",
    "**Now Shuffle the Training set just in case if they are sorted** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2973  9551  8383 10054   295  1125  9119  7263  1675  1950]\n"
     ]
    }
   ],
   "source": [
    "# now shuffling training data. \n",
    "indx = np.array(list(range(len(dogs))))\n",
    "np.random.shuffle(indx)\n",
    "print(indx[:10]) #check the shuffling\n",
    "#shuffle data\n",
    "Xs_train = X_train[indx]  # Shuffled training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10357/10357 [52:25<00:00,  1.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# We need to be in test directory. \n",
    "\n",
    "os.chdir(dpath_test)  # need to be in test data dir\n",
    "# these are the files in the train directory\n",
    "test_dogs = sorted(glob.glob('*.jpg'))\n",
    "\n",
    "# declaring some variables for loop counter and book keeping\n",
    "flag = 0\n",
    "X_test = []  # Test vector\n",
    "\n",
    "Count = 0\n",
    "for w in tqdm(test_dogs):\n",
    "    Count += 1\n",
    "#    if Count == 1000:  # debug just to see if it is working.\n",
    "#        break\n",
    "    if flag == 0:  # . this is used to handle the first picture. should come up with elegant situation.\n",
    "        X_test = rescale(w)\n",
    "        flag = 1\n",
    "    else:\n",
    "        X_test = np.append(X_test, rescale(w), axis=0)  # create a numpy array for test.  \n",
    "\n",
    "X_test= X_test.astype( 'float32' ) / 255  #normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the \"X_train\", \"X_test\", and \"y_train\" for future use.\n",
    "** This is a hdf5 format for large files and has to be retreated by hdf5 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10357, 224, 224, 3) (10222, 224, 224, 3) (10222, 120)\n"
     ]
    }
   ],
   "source": [
    "# Saving the X_train, X_test, and y_train with hdf5 format.\n",
    "# makesure we are in the correct directory\n",
    "os.chdir(dpath)\n",
    "os.getcwd()          # Print Path just to make sure it is in correct directory.\n",
    "# now save to hdf5 \n",
    "# also hdf5 is a hierarchical data which lets you assign tags/groups or subgroups to your data\n",
    "\n",
    "with h5py.File('traindata-org.hdf5','w') as f:   # the -org. refers to pre augmented data set\n",
    "    f.create_dataset('X', data=X_train)\n",
    "    f.create_dataset('Y', data=y_train)\n",
    "with h5py.File('testdata.hdf5','w') as f:\n",
    "    f.create_dataset('X', data=X_test)\n",
    "# check point for the shape.  y_train is one hot encoed \n",
    "print(X_test.shape,Xs_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Method for creating X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10222/10222 [00:37<00:00, 272.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# point to location of the Train images\n",
    "images = glob.glob('/home/ubuntu/train/*.jpg')\n",
    "img_data = []\n",
    "# resize and add new axis to images\n",
    "for i in tqdm(images):\n",
    "    img = image.load_img(i, target_size=(im_H, im_W))\n",
    "    img_data.append(image.img_to_array(img)[np.newaxis, :, :, :])\n",
    "# concatenate the images    \n",
    "tr_img_data_np = np.concatenate(img_data, )\n",
    "# save them as \"unsigned Integer\" for the smaller size. We will use this for Transfer learning Model. \n",
    "tr_img_data_np = tr_img_data_np.astype('uint8')\n",
    "# create the label \n",
    "labels = pd.read_csv(label_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10222, 224, 224, 3) uint8\n"
     ]
    }
   ],
   "source": [
    "print(tr_img_data_np.shape,tr_img_data_np.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10357/10357 [00:37<00:00, 277.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# point to location of the Test images\n",
    "images_Tst = glob.glob('/home/ubuntu/test/*.jpg')\n",
    "img_data_Tst = []\n",
    "# resize and add new axis to images\n",
    "for i in tqdm(images_Tst):\n",
    "    img = image.load_img(i, target_size=(224, 224))\n",
    "    img_data_Tst.append(image.img_to_array(img)[np.newaxis, :, :, :])\n",
    "# concatenate the images    \n",
    "ts_img_data_np = np.concatenate(img_data_Tst, )\n",
    "# save them as \"unsigned Integer\" for the smaller size.  \n",
    "ts_img_data_np = ts_img_data_np.astype('uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Augmentation \n",
    "\n",
    "* **This function peforms various data augmentation techniques to the dataset (Flip, Rotate, Zoom, Shear)**\n",
    "* [Source](https://www.kaggle.com/dhayalkarsahilr/easy-image-augmentation-techniques \"Code Source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function will take each image and create four more images.  \n",
    "'''\n",
    "    @parameters:\n",
    "        dataset: the feature training dataset in numpy array with shape [num_examples, num_rows, num_cols, num_channels] (since it is an image in numpy array)\n",
    "        dataset_labels: the corresponding training labels of the feature training dataset in the same order, and numpy array with shape [num_examples, <anything>]\n",
    "        augmentation_factor: how many times to perform augmentation.\n",
    "        use_random_rotation: whether to use random rotation. default: true\n",
    "        use_random_shift: whether to use random shift. default: true\n",
    "        use_random_shear: whether to use random shear. default: true\n",
    "        use_random_zoom: whether to use random zoom. default: true\n",
    "        \n",
    "    @returns:\n",
    "        augmented_image: augmented dataset\n",
    "        augmented_image_labels: labels corresponding to augmented dataset in order.\n",
    "        \n",
    "    for the augmentation techniques documentation, go here:\n",
    "        https://www.tensorflow.org/api_docs/python/tf/contrib/keras/preprocessing/image/random_rotation\n",
    "        https://www.tensorflow.org/api_docs/python/tf/contrib/keras/preprocessing/image/random_shear\n",
    "        https://www.tensorflow.org/api_docs/python/tf/contrib/keras/preprocessing/image/random_shift\n",
    "        https://www.tensorflow.org/api_docs/python/tf/contrib/keras/preprocessing/image/random_zoom\n",
    "'''\n",
    "def augment_data(dataset, dataset_labels, augementation_factor=1, use_random_rotation=True, use_random_shear=True, use_random_shift=True, use_random_zoom=True):\n",
    "    augmented_image = []\n",
    "    augmented_image_labels = []\n",
    "\n",
    "    for num in tqdm(range(0, dataset.shape[0])):  # tqdm progress bar\n",
    "        for i in range(0, augementation_factor):\n",
    "            # original image:\n",
    "            augmented_image.append(dataset[num])\n",
    "            augmented_image_labels.append(dataset_labels[num])\n",
    "\n",
    "            if use_random_rotation:\n",
    "                \n",
    "                augmented_image.append(tf.contrib.keras.preprocessing.image.random_rotation(dataset[num], 20, row_axis=0, col_axis=1, channel_axis=2))\n",
    "                augmented_image_labels.append(dataset_labels[num])\n",
    "\n",
    "            if use_random_shear:\n",
    "                augmented_image.append(tf.contrib.keras.preprocessing.image.random_shear(dataset[num], 0.2, row_axis=0, col_axis=1, channel_axis=2))\n",
    "                augmented_image_labels.append(dataset_labels[num])\n",
    "\n",
    "            if use_random_shift:\n",
    "                augmented_image.append(tf.contrib.keras.preprocessing.image.random_shift(dataset[num], 0.2, 0.2, row_axis=0, col_axis=1, channel_axis=2))\n",
    "                augmented_image_labels.append(dataset_labels[num])\n",
    "\n",
    "            if use_random_zoom:\n",
    "                # update: zoomrange (second arg) should be tuple of floats\n",
    "                augmented_image.append(tf.contrib.keras.preprocessing.image.random_zoom(dataset[num], (0.9, 0.9), row_axis=0, col_axis=1, channel_axis=2))\n",
    "                augmented_image_labels.append(dataset_labels[num])\n",
    "\n",
    "    return np.array(augmented_image), np.array(augmented_image_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Augmented Images \n",
    "** the aug_image and aug_label. are X_train and y_train **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10222/10222 [07:50<00:00, 22.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# Augment train data set this will increase the data set size by 5X\n",
    "aug_images, aug_labels = augment_data(tr_img_data_np, labels.breed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51110, 224, 224, 3) (51110,) uint8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check point make sure the size and shape are as expected.\n",
    "print(aug_images.shape,aug_labels.shape,aug_images.dtype)\n",
    "# Make sure the data type is expected.\n",
    "aug_images.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10222, 120) float32\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape, y_train.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save X_train and y_train data for later usage.\n",
    "** This is input file with the Augmented images and since the sizer is very large DeepDish.io was used with compresion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the X_train and y_train to a HD5 file with Deep Dish.io \n",
    "Aug_train_data = '/home/ubuntu/train_aug_data.hdf5'\n",
    "dd.io.save(Aug_train_data, {'X': aug_images, 'Y': aug_labels}, compression=('blosc', 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the test_data as hd5 with deepdish.io\n",
    "test_data = '/home/ubuntu/test_data.hdf5'\n",
    "dd.io.save(test_data, {'X': ts_img_data_np}, compression=('blosc', 9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing of the data\n",
    "* Create the X_train and y_train\n",
    "* write the arrays to a file and upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Xs_train = aug_images.astype('float32')/255 \n",
    "Xs_train = aug_images.astype('uint8') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### legacy:  saving files with h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(dpath)\n",
    "with h5py.File('Aug_traindata.hdf5','w') as f:\n",
    "    f.create_dataset('X', data=aug_images)\n",
    "    f.create_dataset('Y', data=aug_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A shuffling of data just in case we need prior to running the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now shuffling training data. this part was done for the CNN style deeplearning. \n",
    "indx = np.array(list(range(len(aug_images))))\n",
    "np.random.shuffle(indx)\n",
    "print(indx[:10]) #check the shuffling\n",
    "#shuffle data\n",
    "Xs_train = aug_images[indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
