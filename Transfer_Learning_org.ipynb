{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog Breed Identification\n",
    "## Farhad Navid \n",
    "\n",
    "### transfer learning with origenal data set\n",
    "\n",
    "* Load data set\n",
    "* Load weights from ImageNet features for pretrained VGG19 model \"block4_pool\".\n",
    "* Run model\n",
    "* Create train and test\n",
    "* Run SVM model\n",
    "* Record the performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "RPC65Oih0GA-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# initialization\n",
    "import matplotlib.pyplot as plt \n",
    "import PIL\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "#import deepdish as dd\n",
    "\n",
    "from array import *\n",
    "from PIL import Image as Img\n",
    "\n",
    "from tqdm import tqdm\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Concatenate, Dense, Dropout, Flatten, Activation, GlobalMaxPooling2D\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D \n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import cohen_kappa_score,confusion_matrix,accuracy_score,classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "K.set_image_dim_ordering( 'tf' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next block of code does represent the Directory structure of the data once the repository was selected.  In this instance the [**AWS**](https://www.AWS.Amazon.com/) (paid service) were utilized.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "T8ly2Efy0GBC"
   },
   "outputs": [],
   "source": [
    "# directory structure of the data\n",
    "\n",
    "dpath_train = '/home/ubuntu/train'      # Data path to training data set\n",
    "dpath_test  = '/home/ubuntu/test'       # Data path to test data set\n",
    "dpath       = '/home/ubuntu'\n",
    "label_f     = '/home/ubuntu/labels.csv' # Path to the label file "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the pre-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10222, 224, 224, 3) uint8 (10222, 120) uint8\n"
     ]
    }
   ],
   "source": [
    "# now read to hdf5 \n",
    "#The processed train data set file  that was created by input_prep file.\n",
    "with h5py.File('train_data.hdf5','r') as f:\n",
    "    X_train = f['X'][()] #the [()] means load all x_train data\n",
    "    y_train = f['Y'][()] # Load all y_train data\n",
    "print(X_train.shape,X_train.dtype,y_train.shape,y_train.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10222, 224, 224, 3) uint8 (10222, 120) uint8\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,X_train.dtype,y_train.shape,y_train.dtype)\n",
    "y_train=y_train.astype('uint8')\n",
    "#y_train[:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### y_train is one hot encoded and need to get it to integer form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the y_train from one hot encoding to integer\n",
    "ytrain_1 = np.array(y_train)\n",
    "ytrain1_rdy = [np.where(r==1)[0][0] for r in ytrain_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain1_rdy[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10222/10222 [05:07<00:00, 33.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# transfer learning\n",
    "# Get the weights from imagenet for the VGG19 model\n",
    "base_model = VGG19(weights='imagenet')\n",
    "# now select the layer to get the features from in this case \"block4_pool\" was selected\n",
    "model = Model(inputs=base_model.input, outputs=base_model.get_layer('block4_pool').output)\n",
    "                    \n",
    "# Create a zero Numpy array with the shape of np.zero((Xs_train.shape[0],(block4_pool_features))) \n",
    "# for this modle the (image#,14,14,512)\n",
    "\n",
    "train_set = np.zeros((X_train.shape[0],14,14,512))\n",
    "\n",
    "## This section of code was written to findout the dimmention of the Block4_pool_features.\n",
    "\n",
    "# x = preprocess_input(X_train[1])  # get one sample of X_train\n",
    "# print(x.shape)                    # Chk the shape \n",
    "# x = np.expand_dims(x,axis=0)      # Ad the image num to the list\n",
    "# print(x.shape)                    # Check the shape\n",
    "\n",
    "# block4_pool_features_org = model.predict(x)  # Create one entry to see the shape\n",
    "\n",
    "# this loop will fill the train_set numpy array (each x_train runs through model with extracted VGG features)\n",
    "for i in tqdm(range(X_train.shape[0])):\n",
    "#    K.clear_session()\n",
    "    x = preprocess_input(X_train[i])\n",
    "    x = np.expand_dims(x,axis=0)\n",
    "    block4_pool_features = model.predict(x)\n",
    "    train_set[i]=block4_pool_features\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Create Train and Test data set for SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test data set\n",
    "train_set = train_set.reshape(train_set.shape[0],-1)\n",
    "X= train_set\n",
    "y= ytrain1_rdy\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM model\n",
    "* **Model Fit**\n",
    "* **Model Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22998.42781996727 seconds\n",
      "12805.782129049301 seconds\n"
     ]
    }
   ],
   "source": [
    "# Run the svm \n",
    "\n",
    "t0=time.time()\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "t1=time.time()\n",
    "print(t1-t0,\"seconds\")\n",
    "\n",
    "# predict \n",
    "t0=time.time()\n",
    "pred_Train=clf.predict(X_train) \n",
    "pred_Test=clf.predict(X_test) \n",
    "t1=time.time()\n",
    "print(t1-t0,\"seconds\")\n",
    "# print(pred_Train[:10],pred_Test[:10])\n",
    "# print(clf.predict([train_set[5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9994517860065777 Train data set cohen kappa score\n",
      "0.0019502601948914178 Test data set cohen kappa score\n",
      "0.9994564626589847 Accuracy Score Train Data set\n",
      "0.007820136852394917 Accuracy Score Test Data set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        71\n",
      "          1       1.00      1.00      1.00       107\n",
      "          2       1.00      1.00      1.00        75\n",
      "          3       1.00      1.00      1.00        95\n",
      "          4       1.00      1.00      1.00        69\n",
      "          5       1.00      1.00      1.00        70\n",
      "          6       1.00      1.00      1.00        90\n",
      "          7       1.00      1.00      1.00       102\n",
      "          8       1.00      1.00      1.00        76\n",
      "          9       1.00      1.00      1.00        95\n",
      "         10       1.00      1.00      1.00        71\n",
      "         11       1.00      1.00      1.00        99\n",
      "         12       1.00      1.00      1.00        71\n",
      "         13       1.00      0.99      0.99        87\n",
      "         14       1.00      1.00      1.00        75\n",
      "         15       1.00      1.00      1.00        75\n",
      "         16       1.00      1.00      1.00        63\n",
      "         17       1.00      1.00      1.00        79\n",
      "         18       1.00      1.00      1.00        69\n",
      "         19       1.00      1.00      1.00        78\n",
      "         20       1.00      1.00      1.00        82\n",
      "         21       1.00      1.00      1.00        66\n",
      "         22       1.00      1.00      1.00        59\n",
      "         23       1.00      0.98      0.99        62\n",
      "         24       1.00      1.00      1.00        68\n",
      "         25       1.00      1.00      1.00        67\n",
      "         26       1.00      1.00      1.00        96\n",
      "         27       1.00      1.00      1.00        68\n",
      "         28       1.00      1.00      1.00        76\n",
      "         29       1.00      1.00      1.00        65\n",
      "         30       1.00      1.00      1.00        81\n",
      "         31       1.00      1.00      1.00        69\n",
      "         32       1.00      1.00      1.00        64\n",
      "         33       1.00      1.00      1.00        81\n",
      "         34       1.00      1.00      1.00        61\n",
      "         35       1.00      1.00      1.00        77\n",
      "         36       1.00      1.00      1.00        67\n",
      "         37       1.00      1.00      1.00        72\n",
      "         38       1.00      1.00      1.00        69\n",
      "         39       1.00      1.00      1.00        82\n",
      "         40       1.00      1.00      1.00        75\n",
      "         41       1.00      1.00      1.00        70\n",
      "         42       1.00      1.00      1.00        99\n",
      "         43       1.00      1.00      1.00        59\n",
      "         44       1.00      1.00      1.00        63\n",
      "         45       1.00      1.00      1.00        65\n",
      "         46       1.00      1.00      1.00        62\n",
      "         47       1.00      1.00      1.00        70\n",
      "         48       1.00      0.98      0.99        61\n",
      "         49       1.00      1.00      1.00        61\n",
      "         50       1.00      1.00      1.00        75\n",
      "         51       1.00      1.00      1.00        66\n",
      "         52       1.00      1.00      1.00        95\n",
      "         53       1.00      1.00      1.00        77\n",
      "         54       1.00      1.00      1.00        76\n",
      "         55       1.00      1.00      1.00        79\n",
      "         56       1.00      1.00      1.00        79\n",
      "         57       1.00      1.00      1.00        74\n",
      "         58       1.00      1.00      1.00        71\n",
      "         59       1.00      1.00      1.00        93\n",
      "         60       1.00      1.00      1.00        87\n",
      "         61       0.98      1.00      0.99        89\n",
      "         62       1.00      1.00      1.00        72\n",
      "         63       1.00      1.00      1.00        78\n",
      "         64       1.00      1.00      1.00        75\n",
      "         65       1.00      1.00      1.00        57\n",
      "         66       1.00      1.00      1.00        69\n",
      "         67       1.00      1.00      1.00        77\n",
      "         68       1.00      1.00      1.00        86\n",
      "         69       1.00      1.00      1.00        96\n",
      "         70       1.00      1.00      1.00        82\n",
      "         71       1.00      1.00      1.00        73\n",
      "         72       1.00      1.00      1.00        63\n",
      "         73       1.00      1.00      1.00       111\n",
      "         74       1.00      1.00      1.00        73\n",
      "         75       1.00      1.00      1.00        89\n",
      "         76       0.99      1.00      0.99        73\n",
      "         77       1.00      1.00      1.00        76\n",
      "         78       1.00      1.00      1.00        85\n",
      "         79       1.00      1.00      1.00        73\n",
      "         80       1.00      1.00      1.00        88\n",
      "         81       1.00      1.00      1.00        74\n",
      "         82       1.00      1.00      1.00        75\n",
      "         83       1.00      1.00      1.00        59\n",
      "         84       1.00      0.99      0.99        82\n",
      "         85       1.00      1.00      1.00        66\n",
      "         86       1.00      1.00      1.00        81\n",
      "         87       1.00      1.00      1.00        99\n",
      "         88       1.00      1.00      1.00        92\n",
      "         89       1.00      1.00      1.00        65\n",
      "         90       1.00      1.00      1.00        81\n",
      "         91       1.00      1.00      1.00        71\n",
      "         92       1.00      1.00      1.00        80\n",
      "         93       1.00      1.00      1.00        89\n",
      "         94       1.00      1.00      1.00       101\n",
      "         95       1.00      1.00      1.00        72\n",
      "         96       1.00      1.00      1.00        78\n",
      "         97       1.00      1.00      1.00       106\n",
      "         98       1.00      1.00      1.00        83\n",
      "         99       1.00      1.00      1.00        71\n",
      "        100       1.00      1.00      1.00        98\n",
      "        101       1.00      1.00      1.00        81\n",
      "        102       1.00      1.00      1.00        83\n",
      "        103       1.00      1.00      1.00        65\n",
      "        104       1.00      1.00      1.00        73\n",
      "        105       1.00      1.00      1.00        71\n",
      "        106       0.99      1.00      0.99        69\n",
      "        107       1.00      1.00      1.00        70\n",
      "        108       1.00      1.00      1.00        62\n",
      "        109       1.00      1.00      1.00        95\n",
      "        110       1.00      0.99      0.99        71\n",
      "        111       1.00      1.00      1.00        72\n",
      "        112       1.00      1.00      1.00        58\n",
      "        113       1.00      1.00      1.00        58\n",
      "        114       1.00      1.00      1.00        75\n",
      "        115       1.00      1.00      1.00        70\n",
      "        116       1.00      1.00      1.00        75\n",
      "        117       0.99      1.00      0.99        86\n",
      "        118       1.00      1.00      1.00        74\n",
      "        119       1.00      1.00      1.00        77\n",
      "\n",
      "avg / total       1.00      1.00      1.00      9199\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         9\n",
      "          1       0.00      0.00      0.00         9\n",
      "          2       0.00      0.00      0.00        11\n",
      "          3       0.00      0.00      0.00        12\n",
      "          4       0.00      0.00      0.00         5\n",
      "          5       0.00      0.00      0.00         8\n",
      "          6       0.00      0.00      0.00        12\n",
      "          7       0.00      0.00      0.00         8\n",
      "          8       0.00      0.00      0.00         6\n",
      "          9       0.00      0.00      0.00        10\n",
      "         10       0.00      0.00      0.00        18\n",
      "         11       0.00      0.00      0.00        15\n",
      "         12       0.00      0.00      0.00         6\n",
      "         13       0.00      0.00      0.00        15\n",
      "         14       0.00      0.00      0.00        10\n",
      "         15       0.00      0.00      0.00        10\n",
      "         16       0.00      0.00      0.00         9\n",
      "         17       0.00      0.00      0.00        12\n",
      "         18       0.00      0.00      0.00         6\n",
      "         19       0.00      0.00      0.00         9\n",
      "         20       0.00      0.00      0.00         4\n",
      "         21       0.00      0.00      0.00         9\n",
      "         22       0.00      0.00      0.00         8\n",
      "         23       0.00      0.00      0.00         4\n",
      "         24       0.00      0.00      0.00         5\n",
      "         25       0.00      0.00      0.00         8\n",
      "         26       0.00      0.00      0.00        10\n",
      "         27       0.00      0.00      0.00         8\n",
      "         28       0.00      0.00      0.00         7\n",
      "         29       0.00      0.00      0.00         6\n",
      "         30       0.00      0.00      0.00        12\n",
      "         31       0.00      0.00      0.00        11\n",
      "         32       0.00      0.00      0.00        10\n",
      "         33       0.00      0.00      0.00         6\n",
      "         34       0.00      0.00      0.00        11\n",
      "         35       0.00      0.00      0.00        12\n",
      "         36       0.00      0.00      0.00         9\n",
      "         37       0.00      0.00      0.00         8\n",
      "         38       0.00      0.00      0.00         5\n",
      "         39       0.00      0.00      0.00         4\n",
      "         40       0.00      0.00      0.00         8\n",
      "         41       0.00      0.00      0.00         5\n",
      "         42       0.00      0.00      0.00        16\n",
      "         43       0.00      0.00      0.00         7\n",
      "         44       0.00      0.00      0.00         9\n",
      "         45       0.00      0.00      0.00         5\n",
      "         46       0.00      0.00      0.00         7\n",
      "         47       0.00      0.00      0.00         5\n",
      "         48       0.00      0.00      0.00         8\n",
      "         49       0.00      0.00      0.00         6\n",
      "         50       0.00      0.00      0.00         6\n",
      "         51       0.00      0.00      0.00         9\n",
      "         52       0.00      0.00      0.00        16\n",
      "         53       0.00      0.00      0.00         5\n",
      "         54       0.00      0.00      0.00         6\n",
      "         55       0.00      0.00      0.00        12\n",
      "         56       0.00      0.00      0.00         9\n",
      "         57       0.00      0.00      0.00         8\n",
      "         58       0.00      0.00      0.00         7\n",
      "         59       0.00      0.00      0.00         8\n",
      "         60       0.00      0.00      0.00         5\n",
      "         61       0.00      0.00      0.00        16\n",
      "         62       0.00      0.00      0.00         9\n",
      "         63       0.00      0.00      0.00         8\n",
      "         64       0.00      0.00      0.00         7\n",
      "         65       0.00      0.00      0.00        10\n",
      "         66       0.00      0.00      0.00         2\n",
      "         67       0.00      0.00      0.00         7\n",
      "         68       0.00      0.00      0.00        13\n",
      "         69       0.00      0.00      0.00        10\n",
      "         70       0.00      0.00      0.00         8\n",
      "         71       0.00      0.00      0.00         8\n",
      "         72       0.00      0.00      0.00        10\n",
      "         73       0.01      1.00      0.01         6\n",
      "         74       1.00      0.14      0.25         7\n",
      "         75       0.00      0.00      0.00        13\n",
      "         76       0.00      0.00      0.00         6\n",
      "         77       0.00      0.00      0.00         2\n",
      "         78       0.00      0.00      0.00         6\n",
      "         79       0.00      0.00      0.00        10\n",
      "         80       0.00      0.00      0.00         7\n",
      "         81       0.00      0.00      0.00         4\n",
      "         82       0.00      0.00      0.00        12\n",
      "         83       0.00      0.00      0.00        10\n",
      "         84       0.00      0.00      0.00        14\n",
      "         85       0.00      0.00      0.00         9\n",
      "         86       0.00      0.00      0.00        11\n",
      "         87       0.00      0.00      0.00        12\n",
      "         88       0.00      0.00      0.00         2\n",
      "         89       0.00      0.00      0.00         7\n",
      "         90       0.00      0.00      0.00         7\n",
      "         91       0.00      0.00      0.00         5\n",
      "         92       0.00      0.00      0.00         4\n",
      "         93       0.00      0.00      0.00        10\n",
      "         94       0.00      0.00      0.00         8\n",
      "         95       0.00      0.00      0.00        14\n",
      "         96       0.00      0.00      0.00         4\n",
      "         97       1.00      0.05      0.10        20\n",
      "         98       0.00      0.00      0.00         5\n",
      "         99       0.00      0.00      0.00         5\n",
      "        100       0.00      0.00      0.00        14\n",
      "        101       0.00      0.00      0.00        14\n",
      "        102       0.00      0.00      0.00         7\n",
      "        103       0.00      0.00      0.00         6\n",
      "        104       0.00      0.00      0.00         6\n",
      "        105       0.00      0.00      0.00         8\n",
      "        106       0.00      0.00      0.00         3\n",
      "        107       0.00      0.00      0.00         8\n",
      "        108       0.00      0.00      0.00         7\n",
      "        109       0.00      0.00      0.00        12\n",
      "        110       0.00      0.00      0.00         9\n",
      "        111       0.00      0.00      0.00         7\n",
      "        112       0.00      0.00      0.00        12\n",
      "        113       0.00      0.00      0.00        11\n",
      "        114       0.00      0.00      0.00        10\n",
      "        115       0.00      0.00      0.00         9\n",
      "        116       0.00      0.00      0.00         6\n",
      "        117       0.00      0.00      0.00         9\n",
      "        118       0.00      0.00      0.00         8\n",
      "        119       0.00      0.00      0.00         5\n",
      "\n",
      "avg / total       0.03      0.01      0.00      1023\n",
      "\n",
      "0.9994568212564354 matrics f1 score train data set\n",
      "0.003641189973957376 matrics f1 score test data set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(cohen_kappa_score(y_train, pred_Train),'Train data set cohen kappa score')\n",
    "print(cohen_kappa_score(y_test, pred_Test),'Test data set cohen kappa score')\n",
    "\n",
    "confusion_matrix(y_train, pred_Train)\n",
    "\n",
    "print(accuracy_score(y_train, pred_Train),'Accuracy Score Train Data set')\n",
    "print(accuracy_score(y_test, pred_Test), 'Accuracy Score Test Data set')\n",
    "\n",
    "print(classification_report(y_train, pred_Train))\n",
    "print(classification_report(y_test, pred_Test))\n",
    "\n",
    "print(metrics.f1_score(y_train, pred_Train,average='weighted'),'matrics f1 score train data set')\n",
    "#22998.42781996727 seconds\n",
    "#12805.782129049301 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 71,   0,   0, ...,   0,   0,   0],\n",
       "       [  0, 107,   0, ...,   0,   0,   0],\n",
       "       [  0,   0,  75, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,  86,   0,   0],\n",
       "       [  0,   0,   0, ...,   0,  74,   0],\n",
       "       [  0,   0,   0, ...,   0,   0,  77]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, pred_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, pred_Test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "Copy of sample_EDA.ipynb",
   "provenance": [
    {
     "file_id": "1cFzLXTPFFpojPWQCDFN9WjfVwkzIoI6B",
     "timestamp": 1525119557988
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
